# ğŸ§­ Project Expedition

**Automated Decision Engine for Performance Marketing**

An AI-powered system that automatically detects marketing anomalies, diagnoses root causes using historical knowledge, and proposes remediation actions.

![Architecture](docs/architecture.png)

## ğŸ¯ What It Does

1. **Detects Anomalies** - Monitors all marketing channels for unexpected metric changes
2. **Investigates Root Causes** - Uses specialized AI agents to analyze what went wrong
3. **Retrieves Historical Context** - RAG-powered memory recalls similar past incidents
4. **Generates Diagnosis** - Multi-persona explanations (Executive â†’ Data Scientist)
5. **Proposes Actions** - Creates executable JSON payloads for platform APIs
6. **Validates Safety** - Triple-Lock Protocol prevents hallucinated recommendations

## ğŸš€ Quick Start

```bash
# 1. Clone and enter directory
git clone https://github.com/YOUR_USERNAME/expedition.git
cd expedition

# 2. Run setup
make setup

# 3. Generate mock data
make mock-data

# 4. Initialize RAG knowledge base
make init-rag

# 5. Run the dashboard
make run
```

Open http://localhost:8501 in your browser.

## ğŸ“ Project Structure

```
expedition/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_layer/           # Data abstraction (mock â†” production)
â”‚   â”‚   â”œâ”€â”€ interfaces/       # Abstract base classes
â”‚   â”‚   â”œâ”€â”€ mock/             # CSV-based mock data
â”‚   â”‚   â””â”€â”€ connectors/       # BigQuery, CreatorIQ (production)
â”‚   â”‚
â”‚   â”œâ”€â”€ intelligence/         # LLM layer (Gemini)
â”‚   â”‚   â”œâ”€â”€ models.py         # Tiered model access
â”‚   â”‚   â””â”€â”€ prompts/          # All LLM prompts
â”‚   â”‚
â”‚   â”œâ”€â”€ nodes/                # LangGraph nodes
â”‚   â”‚   â”œâ”€â”€ preflight.py      # Data freshness check
â”‚   â”‚   â”œâ”€â”€ router.py         # Routes to specialists
â”‚   â”‚   â”œâ”€â”€ investigators/    # Paid media, Influencer
â”‚   â”‚   â”œâ”€â”€ memory/           # RAG retrieval
â”‚   â”‚   â”œâ”€â”€ explainer/        # Diagnosis synthesis
â”‚   â”‚   â”œâ”€â”€ proposer/         # Action generation
â”‚   â”‚   â””â”€â”€ critic/           # Triple-Lock validation
â”‚   â”‚
â”‚   â”œâ”€â”€ action_layer/         # API execution (mock â†” production)
â”‚   â”‚   â”œâ”€â”€ interfaces/       # Abstract executor
â”‚   â”‚   â”œâ”€â”€ mock/             # Logs without executing
â”‚   â”‚   â””â”€â”€ connectors/       # Google/Meta/TikTok APIs
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/              # Pydantic models
â”‚   â””â”€â”€ graph.py              # LangGraph definition
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ mock_csv/             # Generated mock data
â”‚   â”œâ”€â”€ post_mortems/         # Historical incidents for RAG
â”‚   â””â”€â”€ embeddings/           # ChromaDB persistence
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_mock_data.py
â”‚   â””â”€â”€ init_vector_store.py
â”‚
â”œâ”€â”€ app.py                    # Streamlit dashboard
â””â”€â”€ Makefile                  # All commands
```

## ğŸ”§ Configuration

### Environment Variables

Copy `.env.example` to `.env` and configure:

```bash
# For mock mode (default) - no GCP needed
DATA_LAYER_MODE=mock
ACTION_LAYER_MODE=mock

# For production - requires GCP credentials
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_APPLICATION_CREDENTIALS=./credentials/sa-key.json
DATA_LAYER_MODE=production
ACTION_LAYER_MODE=production
```

### Tiered Intelligence

| Tier | Model | Use Case | Cost |
|------|-------|----------|------|
| Tier 1 | gemini-2.0-flash | Routing, data fetching | Low |
| Tier 2 | gemini-2.5-pro | Reasoning, diagnosis | High |

## ğŸ”„ Switching Mock â†’ Production

The entire system is designed for easy swapping:

```bash
# In .env, change these two lines:
DATA_LAYER_MODE=production
ACTION_LAYER_MODE=production

# Then implement:
# 1. src/data_layer/connectors/bigquery.py (your BigQuery tables)
# 2. src/action_layer/connectors/*.py (your API credentials)
```

All nodes, prompts, and the dashboard work unchanged.

## ğŸ“Š Supported Channels

### Paid Media
- Google Search, PMax, Display, YouTube
- Meta (Facebook/Instagram)
- TikTok
- LinkedIn
- Programmatic

### Influencer
- CreatorIQ integration
- Platform-specific metrics
- Causal/incremental analysis

### Offline
- Direct mail
- TV, Radio
- Out-of-home
- Events

## ğŸ§  Architecture

### LangGraph Flow

```
Pre-Flight â†’ Detect â†’ Router â†’ Investigator â†’ Memory â†’ Explainer â†’ Critic â†’ Proposer
                         â†“
                    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                    â”‚         â”‚
               Paid Media  Influencer
```

### Key Design Patterns

1. **Data Abstraction** - Interfaces with mock/production implementations
2. **Tiered Intelligence** - Right-size models for each task
3. **RAG Memory** - ChromaDB for semantic search of past incidents
4. **Triple-Lock Protocol** - Critic validates before proposing actions
5. **Human-in-the-Loop** - Actions require approval before execution

## ğŸ›¡ï¸ Triple-Lock Protocol

The Critic node applies three validation checks:

1. **Data Grounding** - Every claim must reference specific data
2. **Evidence Verification** - Conclusions must follow from evidence
3. **Hallucination Check** - Flag claims beyond provided data

Actions are blocked if hallucination risk > 50%.

## ğŸ“ˆ Dashboard Features

- **Anomaly Dashboard** - Real-time status of all channels
- **Investigation View** - Deep dive into specific anomalies
- **Multi-Persona Diagnosis** - Switch between Executive/Technical views
- **Action Approval** - Review and approve proposed changes
- **Historical Context** - View similar past incidents

## ğŸ§ª Testing

```bash
# Run all tests
make test

# Run with coverage
pytest tests/ -v --cov=src

# Test specific module
pytest tests/unit/test_data_layer.py
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run `make lint` and `make test`
5. Submit a pull request

## ğŸ“ License

MIT License - see LICENSE file

## ğŸ™ Acknowledgments

Built for GoFundMe's Growth Science team.

---

**Questions?** Open an issue or reach out to the Decision Science team.
