# ğŸ§­ Project Expedition

**Automated Decision Engine for Performance Marketing**

An AI-powered system that automatically detects marketing anomalies, diagnoses root causes using historical knowledge, and proposes remediation actions across all marketing channels.

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Repository:** [github.com/Nikhil-Kr/Performance-Marketing-DecisionEngine](https://github.com/Nikhil-Kr/Performance-Marketing-DecisionEngine)

---

## ğŸ¯ What It Does

1. **Detects Anomalies** â€” Monitors all marketing channels for unexpected metric changes (CPA spikes, ROAS drops, conversion collapses)
2. **Investigates Root Causes** â€” Routes to specialized AI investigators (Paid Media, Influencer, Offline)
3. **Retrieves Historical Context** â€” RAG-powered memory recalls similar past incidents and their resolutions
4. **Enriches with Market Data** â€” Pulls competitor intelligence, MMM saturation curves, MTA attribution
5. **Generates Multi-Persona Diagnosis** â€” Executive summary â†’ Technical details (4 audience levels)
6. **Proposes Aligned Actions** â€” LLM selects actions that match its own diagnosis (no keyword mismatch)
7. **Validates Safety** â€” Triple-Lock Protocol prevents hallucinated recommendations
8. **Simulates Impact** â€” 7-day projection charts show baseline vs. action scenarios

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| **Time-Travel Analysis** | Analyze anomalies as of any historical date |
| **MMM Guardrails** | Blocks budget increases on saturated channels |
| **MTA Comparison** | Shows Last-Click vs Data-Driven attribution |
| **Competitor Intelligence** | Surfaces relevant competitor activity |
| **Market Trends** | Google Trends overlay on performance charts |
| **Impact Simulation** | Visual forecast of action outcomes |
| **Batch Processing** | Process multiple anomalies with Slack notifications |
| **Mock â†” Production** | Switch data sources with one env variable |

---

## ğŸš€ Quick Start

```bash
# 1. Clone the repository
git clone https://github.com/Nikhil-Kr/Performance-Marketing-DecisionEngine.git
cd Performance-Marketing-DecisionEngine

# 2. Run setup (creates venv, installs dependencies)
make setup

# 3. Configure environment
cp .env.example .env
# Edit .env with your GCP project ID

# 4. Authenticate with GCP (for Gemini API)
gcloud auth application-default login

# 5. Generate mock data
make mock-data

# 6. Initialize RAG knowledge base
make init-rag

# 7. Run the dashboard
make run
```

Open **http://localhost:8501** in your browser.

---

## ğŸ“Š Supported Channels (15 Total)

### Digital â€” Paid Search & Shopping
- Google Search
- Google Performance Max
- Google Display
- Google YouTube

### Digital â€” Social
- Meta Ads (Facebook/Instagram)
- TikTok Ads
- LinkedIn Ads

### Digital â€” Programmatic & Affiliate
- Programmatic (DV360, The Trade Desk)
- Affiliate Networks

### Offline
- TV (Linear & CTV)
- Podcast
- Radio
- Direct Mail
- Out-of-Home (OOH)
- Events

### Creator Economy
- Influencer Campaigns (CreatorIQ integration)

---

## ğŸ—ï¸ Architecture

### LangGraph Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preflightâ”‚â”€â”€â”€â–¶â”‚ Detect â”‚â”€â”€â”€â–¶â”‚ Router â”‚â”€â”€â”€â–¶â”‚ Investigator â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â–¼                    â–¼                    â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Paid Media â”‚      â”‚ Influencer â”‚      â”‚  Offline   â”‚
                       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                             â”‚                   â”‚                   â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Proposer â”‚â—€â”€â”€â”€â”‚ Critic â”‚â—€â”€â”€â”€â”‚Explainerâ”‚â—€â”€â”€â”€â”‚ Memory â”‚â—€â”€â”€â”€â”‚(combines)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Node Descriptions

| Node | Purpose | Model Tier |
|------|---------|------------|
| **Preflight** | Validates data freshness | â€” |
| **Detect** | Finds anomalies via z-score | â€” |
| **Router** | Classifies channel type | Tier 1 (Flash) |
| **Investigator** | Deep-dives into root cause | Tier 2 (Pro) |
| **Memory** | RAG retrieval of past incidents | Embeddings |
| **Explainer** | Synthesizes diagnosis + selects actions | Tier 2 (Pro) |
| **Critic** | Triple-Lock validation | Tier 2 (Pro) |
| **Proposer** | Formats actions for execution | â€” |

---

## ğŸ“ Project Structure

```
expedition/
â”œâ”€â”€ app.py                    # Streamlit dashboard
â”œâ”€â”€ Makefile                  # All commands
â”œâ”€â”€ .env.example              # Configuration template
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ graph.py              # LangGraph orchestration
â”‚   â”œâ”€â”€ batch.py              # Batch processing mode
â”‚   â”‚
â”‚   â”œâ”€â”€ data_layer/           # Data abstraction
â”‚   â”‚   â”œâ”€â”€ interfaces/       # Abstract base classes
â”‚   â”‚   â”œâ”€â”€ mock/             # CSV-based mock data
â”‚   â”‚   â”‚   â”œâ”€â”€ marketing.py  # Channel performance
â”‚   â”‚   â”‚   â”œâ”€â”€ influencer.py # Creator campaigns
â”‚   â”‚   â”‚   â”œâ”€â”€ strategy.py   # MMM & MTA data
â”‚   â”‚   â”‚   â””â”€â”€ market.py     # Competitor & trends
â”‚   â”‚   â””â”€â”€ connectors/       # Production (BigQuery, CreatorIQ)
â”‚   â”‚
â”‚   â”œâ”€â”€ intelligence/         # LLM layer
â”‚   â”‚   â”œâ”€â”€ models.py         # Tiered Gemini access
â”‚   â”‚   â””â”€â”€ prompts/          # All LLM prompts
â”‚   â”‚       â”œâ”€â”€ router.py
â”‚   â”‚       â”œâ”€â”€ investigator.py
â”‚   â”‚       â”œâ”€â”€ explainer.py  # Includes action catalog
â”‚   â”‚       â””â”€â”€ critic.py
â”‚   â”‚
â”‚   â”œâ”€â”€ nodes/                # LangGraph nodes
â”‚   â”‚   â”œâ”€â”€ preflight.py
â”‚   â”‚   â”œâ”€â”€ router.py
â”‚   â”‚   â”œâ”€â”€ investigators/
â”‚   â”‚   â”‚   â”œâ”€â”€ paid_media.py
â”‚   â”‚   â”‚   â”œâ”€â”€ influencer.py
â”‚   â”‚   â”‚   â””â”€â”€ offline.py
â”‚   â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”‚   â””â”€â”€ retriever.py  # ChromaDB RAG
â”‚   â”‚   â”œâ”€â”€ explainer/
â”‚   â”‚   â”‚   â””â”€â”€ synthesizer.py
â”‚   â”‚   â”œâ”€â”€ critic/
â”‚   â”‚   â”‚   â””â”€â”€ validator.py
â”‚   â”‚   â””â”€â”€ proposer/
â”‚   â”‚       â””â”€â”€ action_mapper.py
â”‚   â”‚
â”‚   â”œâ”€â”€ action_layer/         # Execution layer
â”‚   â”‚   â”œâ”€â”€ interfaces/       # Abstract executor
â”‚   â”‚   â”œâ”€â”€ mock/             # Logs without executing
â”‚   â”‚   â””â”€â”€ connectors/       # Platform APIs
â”‚   â”‚       â”œâ”€â”€ google_ads.py
â”‚   â”‚       â”œâ”€â”€ meta_ads.py
â”‚   â”‚       â”œâ”€â”€ tiktok_ads.py
â”‚   â”‚       â”œâ”€â”€ linkedin_ads.py
â”‚   â”‚       â”œâ”€â”€ programmatic.py
â”‚   â”‚       â”œâ”€â”€ affiliate.py
â”‚   â”‚       â””â”€â”€ offline.py    # Slack-based notifications
â”‚   â”‚
â”‚   â”œâ”€â”€ notifications/
â”‚   â”‚   â””â”€â”€ slack.py          # Slack webhook integration
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ state.py          # Pydantic state models
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ config.py         # Settings management
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ mock_csv/             # Generated mock data (15 channels)
â”‚   â”œâ”€â”€ post_mortems/         # Historical incidents for RAG
â”‚   â””â”€â”€ embeddings/           # ChromaDB persistence
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_mock_data.py # Creates realistic mock data
â”‚   â””â”€â”€ init_vector_store.py  # Initializes RAG embeddings
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_expedition.py
```

---

## âš™ï¸ Configuration

### Environment Variables

Copy `.env.example` to `.env` and configure:

```bash
# ===========================================
# LAYER MODES (mock or production)
# ===========================================
DATA_LAYER_MODE=mock
ACTION_LAYER_MODE=mock

# ===========================================
# GOOGLE CLOUD / VERTEX AI
# ===========================================
GOOGLE_CLOUD_PROJECT=your-project-id
VERTEX_AI_LOCATION=us-central1

# ===========================================
# GEMINI MODELS (Tiered Intelligence)
# ===========================================
GEMINI_TIER1_MODEL=gemini-2.0-flash
GEMINI_TIER2_MODEL=gemini-2.5-pro
EMBEDDING_MODEL=text-embedding-004

# ===========================================
# NOTIFICATIONS
# ===========================================
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...
SLACK_CHANNEL_ALERTS=#marketing-alerts
SLACK_CHANNEL_MEDIA_BUYING=#media-buying

# ===========================================
# PLATFORM CREDENTIALS (Production Only)
# ===========================================
# See .env.example for full list
```

### Tiered Intelligence

| Tier | Model | Use Case | Cost |
|------|-------|----------|------|
| Tier 1 | gemini-2.0-flash | Routing, classification | Low |
| Tier 2 | gemini-2.5-pro | Investigation, diagnosis, validation | Higher |

Models are configurable via `.env` â€” upgrade to Gemini 3 when available.

---

## ğŸ”„ Mock â†’ Production

The entire system is designed for seamless environment switching:

```bash
# In .env, change these two lines:
DATA_LAYER_MODE=production
ACTION_LAYER_MODE=production

# Then implement your connectors:
# 1. src/data_layer/connectors/bigquery.py (your data warehouse)
# 2. src/action_layer/connectors/*.py (add API credentials)
```

**All nodes, prompts, and the dashboard work unchanged.**

### What Changes Per Mode

| Component | Mock Mode | Production Mode |
|-----------|-----------|-----------------|
| Channel Data | CSV files | BigQuery tables |
| Influencer Data | CSV files | CreatorIQ API |
| Action Execution | Logged only | Real API calls |
| Offline Actions | Logged only | Slack alerts to media team |

---

## ğŸ›¡ï¸ Triple-Lock Protocol

The Critic node applies three validation checks before any action is proposed:

1. **Data Grounding** â€” Every claim must reference specific metrics
2. **Evidence Verification** â€” Conclusions must logically follow from evidence
3. **Hallucination Check** â€” Flags claims that go beyond provided data

Actions are blocked if hallucination risk > 50%.

---

## ğŸ“ˆ Dashboard Features

### Investigation View
- **Anomaly Summary** â€” Metric, severity, deviation %
- **Channel Performance** â€” Historical trend with anomaly highlighted
- **Market Overlay** â€” Google Trends comparison
- **Competitor Activity** â€” Recent competitive moves

### Strategy Context
- **MMM Guardrails** â€” Saturation status and recommendation
- **MTA Comparison** â€” Attribution model differences

### Diagnosis
- **Multi-Persona Views** â€” Executive, Director, Marketer, Data Scientist
- **Historical Context** â€” Similar past incidents from RAG
- **Confidence Score** â€” Model's certainty in diagnosis

### Actions
- **Proposed Actions** â€” With risk level and estimated impact
- **Impact Simulation** â€” 7-day projection chart
- **Approval Flow** â€” Review before execution

---

## ğŸ§ª Testing & Development

```bash
# Run all tests
make test

# Run with verbose output
pytest tests/ -v

# Lint code
make lint

# Format code
make format

# Test Slack connection
make test-slack
```

---

## ğŸ“‹ Available Make Commands

```bash
make help           # Show all commands
make setup          # Full setup (venv, deps, .env)
make mock-data      # Generate mock marketing data
make init-rag       # Initialize ChromaDB vector store
make run            # Run Streamlit dashboard
make run-batch      # Process anomalies in batch mode
make run-batch-notify  # Batch mode with Slack notifications
make test-slack     # Test Slack webhook
make test           # Run tests
make lint           # Lint code
make clean          # Remove generated files
make quickstart     # Full setup + run (one command)
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Run `make lint` and `make test`
5. Commit (`git commit -m 'Add amazing feature'`)
6. Push (`git push origin feature/amazing-feature`)
7. Open a Pull Request

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

Built for marketing decision science teams who need automated anomaly detection and diagnosis at scale.

---

**Questions or Issues?** Open an issue on GitHub or reach out to the maintainers.